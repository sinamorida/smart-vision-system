{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import sqlite3\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# =====================\n",
    "# Configuration Settings\n",
    "# =====================\n",
    "\n",
    "IMG_SIZE = 224\n",
    "FACE_THRESHOLD = 0.65\n",
    "GPU_MEM_LIMIT = 1536  # MB\n",
    "DATABASE_FILE = \"face_database.db\"\n",
    "MIN_CAPTURE_INTERVAL = 5  # seconds\n",
    "\n",
    "# =====================\n",
    "# Initialize Models\n",
    "# =====================\n",
    "app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "\n",
    "app.prepare(ctx_id=0)\n",
    "# GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=GPU_MEM_LIMIT)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Config Error: {e}\")\n",
    "\n",
    "# Face Detection Model\n",
    "face_detector = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt\", \n",
    "    \"res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    ")\n",
    "\n",
    "# Image Classification Model\n",
    "classification_model = tf.keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# Database Functions\n",
    "# =====================\n",
    "def init_db():\n",
    "    \"\"\"Initialize SQLite database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS faces \n",
    "                (id INTEGER PRIMARY KEY, name TEXT, embedding BLOB)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def save_to_db(name, embedding):\n",
    "    \"\"\"Save face embedding to database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"INSERT INTO faces (name, embedding) VALUES (?, ?)\",\n",
    "             (name, embedding.tobytes()))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def load_from_db():\n",
    "    \"\"\"Load all face embeddings from database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT name, embedding FROM faces\")\n",
    "    data = {row[0]: np.frombuffer(row[1], dtype=np.float32) for row in c.fetchall()}\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "# =====================\n",
    "# Image Processing\n",
    "# =====================\n",
    "def process_face(image):\n",
    "    \"\"\"Preprocess face image for embedding\"\"\"\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return (image / 127.5) - 1.0\n",
    "\n",
    "def get_embedding(image):\n",
    "    \"\"\"Generate face embedding using InsightFace\"\"\"\n",
    "    faces = app.get(image)\n",
    "    if faces:\n",
    "        return faces[0].embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classify_image(image):\n",
    "    \"\"\"Classify image using ResNet50V2\"\"\"\n",
    "    img = cv2.resize(image, (224, 224))\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = classification_model.predict(np.expand_dims(img, 0))\n",
    "    return tf.keras.applications.resnet_v2.decode_predictions(preds, top=3)[0]\n",
    "\n",
    "def similarity_search(query_img, threshold):\n",
    "    \"\"\"Search for similar faces in database\"\"\"\n",
    "    embedding = get_embedding(query_img)\n",
    "    if embedding is None:\n",
    "        return []\n",
    "    \n",
    "    database = load_from_db()\n",
    "    \n",
    "    results = []\n",
    "    for name, db_emb in database.items():\n",
    "        similarity = cosine_similarity([embedding], [db_emb])[0][0]\n",
    "        if similarity >= threshold:\n",
    "            results.append((name, similarity))\n",
    "    \n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search_from_image(image_path,thresh):\n",
    "    image = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    face_detector.setInput(blob)\n",
    "    detections = face_detector.forward()\n",
    "\n",
    "    faces = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0,0,i,2]\n",
    "        if confidence > 0.9:\n",
    "            box = detections[0,0,i,3:7] * np.array([image.shape[1], image.shape[0]]*2)\n",
    "            faces.append(box.astype(\"int\"))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = image[y:h, x:x+w]\n",
    "        \n",
    "    return similarity_search(face_img,thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_face_identifier():\n",
    "    init_db()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    db = load_from_db()\n",
    "\n",
    "    register_mode = False\n",
    "    embeddings = []\n",
    "    current_name = \"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        face_detector.setInput(blob)\n",
    "        detections = face_detector.forward()\n",
    "\n",
    "        faces = []\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0,0,i,2]\n",
    "            if confidence > 0.9:\n",
    "                box = detections[0,0,i,3:7] * np.array([frame.shape[1], frame.shape[0]]*2)\n",
    "                faces.append(box.astype(\"int\"))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:h, x:x+w]\n",
    "            \n",
    "            if register_mode:\n",
    "                embeddings.append(get_embedding(face_img))\n",
    "                cv2.putText(frame, f\"Captured: {len(embeddings)}/50\", (x+5,y-30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "            else:\n",
    "                emb = get_embedding(face_img)\n",
    "                best_match = (\"Unknown\", 0.0)\n",
    "                for name, db_emb in db.items():\n",
    "                    similarity = cosine_similarity([emb], [db_emb])[0][0]\n",
    "                    if similarity > best_match[1]:\n",
    "                        best_match = (name, similarity)\n",
    "                \n",
    "                color = (0,255,0) if best_match[1] > FACE_THRESHOLD else (0,0,255)\n",
    "                cv2.rectangle(frame, (x,y), (w,h), color, 2)\n",
    "                cv2.putText(frame, f\"{best_match[0]} ({best_match[1]:.0%})\", \n",
    "                           (x+5,y-30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        db = load_from_db()                \n",
    "        \n",
    "        cv2.imshow('Smart Vision System', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            current_name = input(\"Enter name: \")\n",
    "            register_mode = True\n",
    "        elif key == ord(' ') and register_mode and len(embeddings) >= 50:\n",
    "            avg_emb = np.mean(embeddings, axis=0)\n",
    "            save_to_db(current_name, avg_emb)\n",
    "            db = load_from_db()\n",
    "            register_mode = False\n",
    "            embeddings = []\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (73,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mwebcam_face_identifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mwebcam_face_identifier\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m     register_mode = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m register_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embeddings) >= \u001b[32m50\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     avg_emb = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     save_to_db(current_name, avg_emb)\n\u001b[32m     66\u001b[39m     db = load_from_db()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3501\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3502\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3505\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf/lib/python3.12/site-packages/numpy/core/_methods.py:102\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_mean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     arr = \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     is_float16_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    106\u001b[39m     rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (73,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "webcam_face_identifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_from_webcam():\n",
    "    \n",
    "    model_path = 'yolo11m.pt' \n",
    "    model = YOLO(model_path)\n",
    "\n",
    "     \n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        \n",
    "        results = model.predict(frame,)\n",
    "\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                class_id = box.cls[0]\n",
    "                confidence = box.conf[0]\n",
    "\n",
    "                if confidence > 0.5:\n",
    "                    label = model.names[int(class_id)]\n",
    "                    color = (0, 255, 0)\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        \n",
    "        cv2.imshow('Object Detection', frame)\n",
    "\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 177.1ms\n",
      "Speed: 5.8ms preprocess, 177.1ms inference, 368.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 82.4ms\n",
      "Speed: 5.1ms preprocess, 82.4ms inference, 7.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 5.0ms preprocess, 82.8ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 5.0ms preprocess, 82.8ms inference, 9.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 6.4ms preprocess, 83.0ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 6.9ms preprocess, 83.1ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 7.6ms preprocess, 83.0ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 6.0ms preprocess, 83.3ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 6.4ms preprocess, 84.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 8.0ms preprocess, 83.6ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 6.2ms preprocess, 83.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 6.0ms preprocess, 83.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 6.7ms preprocess, 83.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 8.8ms preprocess, 83.4ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 5.9ms preprocess, 83.4ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.4ms preprocess, 83.0ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 4.1ms preprocess, 82.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.9ms preprocess, 83.4ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 7.4ms preprocess, 83.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 7.4ms preprocess, 83.1ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 6.4ms preprocess, 83.5ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.8ms preprocess, 83.3ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.0ms preprocess, 83.3ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 7.2ms preprocess, 83.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 4.9ms preprocess, 83.5ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 6.3ms preprocess, 83.6ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.6ms preprocess, 83.3ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.4ms preprocess, 83.1ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.7ms preprocess, 83.4ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 3.8ms preprocess, 83.2ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 6.2ms preprocess, 83.1ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.3ms preprocess, 83.2ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.4ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 4.1ms preprocess, 83.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.2ms preprocess, 83.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 6.0ms preprocess, 83.2ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 4.4ms preprocess, 83.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.6ms preprocess, 83.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.3ms preprocess, 83.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.7ms preprocess, 83.0ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 3.6ms preprocess, 83.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 7.6ms preprocess, 83.3ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.8ms preprocess, 83.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 6.3ms preprocess, 83.2ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.0ms preprocess, 83.2ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 5.2ms preprocess, 83.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.8ms preprocess, 83.1ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 6.1ms preprocess, 83.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.3ms preprocess, 83.4ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 6.2ms preprocess, 83.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.7ms\n",
      "Speed: 6.0ms preprocess, 83.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.1ms preprocess, 83.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.1ms preprocess, 83.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 5.2ms preprocess, 83.4ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 6.8ms preprocess, 83.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 4.6ms preprocess, 83.3ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.8ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.9ms preprocess, 83.3ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 3.9ms preprocess, 83.3ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.6ms preprocess, 83.0ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 5.8ms preprocess, 83.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.8ms preprocess, 83.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.2ms preprocess, 83.3ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.0ms preprocess, 83.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.2ms preprocess, 83.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 6.4ms preprocess, 83.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.9ms preprocess, 83.2ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.1ms preprocess, 83.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 3.9ms preprocess, 83.4ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 3.8ms preprocess, 83.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.0ms preprocess, 83.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 3.7ms preprocess, 83.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.9ms preprocess, 83.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 3.3ms preprocess, 83.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 6.8ms preprocess, 83.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.3ms preprocess, 83.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 3.9ms preprocess, 83.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.0ms preprocess, 83.2ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 6.6ms preprocess, 83.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 4.1ms preprocess, 83.3ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 6.6ms preprocess, 83.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.1ms preprocess, 83.3ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.0ms preprocess, 83.3ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.7ms preprocess, 83.0ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.6ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.8ms preprocess, 83.1ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 3.7ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.7ms\n",
      "Speed: 7.3ms preprocess, 83.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.0ms preprocess, 83.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.4ms preprocess, 83.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.2ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.5ms\n",
      "Speed: 5.2ms preprocess, 83.5ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.7ms preprocess, 83.1ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.6ms\n",
      "Speed: 4.1ms preprocess, 83.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.7ms preprocess, 83.3ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.3ms preprocess, 83.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.2ms preprocess, 83.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.1ms preprocess, 83.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.3ms preprocess, 83.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.0ms preprocess, 83.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.7ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 6.6ms preprocess, 83.3ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.1ms preprocess, 83.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.3ms preprocess, 83.1ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.5ms preprocess, 83.0ms inference, 8.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 8.3ms preprocess, 83.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 7.7ms preprocess, 83.3ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 3.9ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.6ms preprocess, 83.0ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.2ms preprocess, 83.3ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 6.9ms preprocess, 83.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.5ms preprocess, 83.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.2ms preprocess, 83.0ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 4.5ms preprocess, 82.8ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.1ms preprocess, 83.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 5.0ms preprocess, 83.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.7ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.3ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.4ms preprocess, 83.1ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 4.2ms preprocess, 82.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.1ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.8ms preprocess, 83.3ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 6.5ms preprocess, 82.9ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.2ms preprocess, 83.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.0ms preprocess, 83.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 3.6ms preprocess, 82.8ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 3.9ms preprocess, 83.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.1ms preprocess, 83.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.1ms preprocess, 83.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.2ms preprocess, 83.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 4.9ms preprocess, 82.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 7.1ms preprocess, 83.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.1ms preprocess, 83.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.6ms preprocess, 83.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 5.6ms preprocess, 83.0ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 5.9ms preprocess, 83.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 83.2ms\n",
      "Speed: 5.4ms preprocess, 83.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.4ms preprocess, 83.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 5.7ms preprocess, 83.0ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.1ms preprocess, 83.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 7.6ms preprocess, 83.0ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.4ms preprocess, 83.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 3.9ms preprocess, 82.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 6.9ms preprocess, 83.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 4.4ms preprocess, 82.9ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.1ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.5ms preprocess, 83.3ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 6.5ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.9ms preprocess, 83.3ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.3ms preprocess, 83.3ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.8ms\n",
      "Speed: 5.3ms preprocess, 82.8ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.9ms preprocess, 83.2ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.3ms preprocess, 83.0ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 3.8ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 5.9ms preprocess, 82.9ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.2ms preprocess, 83.1ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.5ms\n",
      "Speed: 4.6ms preprocess, 83.5ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.1ms preprocess, 83.1ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 7.2ms preprocess, 83.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.1ms preprocess, 83.2ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.2ms preprocess, 83.1ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.0ms preprocess, 83.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.4ms preprocess, 83.1ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 5.1ms preprocess, 83.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 5.6ms preprocess, 83.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 5.6ms preprocess, 83.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 4.3ms preprocess, 83.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 6.8ms preprocess, 83.1ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.8ms preprocess, 83.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.2ms preprocess, 83.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 6.0ms preprocess, 83.1ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 6.1ms preprocess, 83.3ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 5.6ms preprocess, 83.4ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.2ms preprocess, 83.3ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 6.0ms preprocess, 83.0ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.2ms preprocess, 83.2ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 6.8ms preprocess, 83.0ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.3ms preprocess, 83.2ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.5ms preprocess, 83.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.2ms preprocess, 83.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 6.6ms preprocess, 83.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.9ms preprocess, 83.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.9ms preprocess, 83.2ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.8ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.7ms preprocess, 83.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.3ms preprocess, 83.0ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.0ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.9ms\n",
      "Speed: 7.3ms preprocess, 83.9ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 6.7ms preprocess, 83.2ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.1ms preprocess, 83.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 7.1ms preprocess, 83.4ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 5.5ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.7ms preprocess, 83.3ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 3.9ms preprocess, 82.9ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 5.2ms preprocess, 83.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 3.8ms preprocess, 83.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.9ms\n",
      "Speed: 5.2ms preprocess, 83.9ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 3.9ms preprocess, 83.0ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.8ms preprocess, 83.1ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 3.8ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 6.2ms preprocess, 83.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.1ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.4ms preprocess, 83.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.3ms\n",
      "Speed: 5.7ms preprocess, 83.3ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.7ms\n",
      "Speed: 3.5ms preprocess, 83.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.0ms\n",
      "Speed: 4.7ms preprocess, 83.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 5.7ms preprocess, 82.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 5.2ms preprocess, 82.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.9ms preprocess, 83.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.9ms\n",
      "Speed: 6.6ms preprocess, 83.9ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 7.2ms preprocess, 83.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.5ms\n",
      "Speed: 5.1ms preprocess, 83.5ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.4ms\n",
      "Speed: 7.6ms preprocess, 83.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 4.2ms preprocess, 82.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 82.8ms\n",
      "Speed: 4.8ms preprocess, 82.8ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 83.6ms\n",
      "Speed: 8.5ms preprocess, 83.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 3.8ms preprocess, 83.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 6.2ms preprocess, 83.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 83.1ms\n",
      "Speed: 4.6ms preprocess, 83.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 4.0ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.2ms\n",
      "Speed: 4.5ms preprocess, 83.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.7ms preprocess, 83.1ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 7.1ms preprocess, 83.2ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 5.6ms preprocess, 84.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 6.3ms preprocess, 83.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.3ms preprocess, 83.3ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.7ms preprocess, 83.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 6.0ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.1ms preprocess, 83.1ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 5.0ms preprocess, 82.8ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.7ms\n",
      "Speed: 4.3ms preprocess, 82.7ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 6.1ms preprocess, 83.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 4.6ms preprocess, 83.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 5.2ms preprocess, 83.4ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.5ms preprocess, 83.1ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 4.0ms preprocess, 83.3ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 4.7ms preprocess, 83.2ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 5.1ms preprocess, 83.4ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 4.2ms preprocess, 83.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 7.2ms preprocess, 83.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.1ms\n",
      "Speed: 5.1ms preprocess, 83.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 4.7ms preprocess, 82.9ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 83.2ms\n",
      "Speed: 5.7ms preprocess, 83.2ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 7.5ms preprocess, 83.1ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 5.8ms preprocess, 83.1ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 5.6ms preprocess, 83.5ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 4.7ms preprocess, 83.0ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 5.9ms preprocess, 83.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "object_detection_from_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x544 1 cat, 190.1ms\n",
      "Speed: 6.8ms preprocess, 190.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x41274140) is not the object's thread (0x336baf50).\n",
      "Cannot move to target thread (0x41274140)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def object_detection_from_image(image_path):\n",
    "\n",
    "    model_path = \"yolo11m.pt\"\n",
    "    \n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "  \n",
    "    results = model.predict(img,)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            class_id = box.cls[0]\n",
    "            confidence = box.conf[0]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                label = model.names[int(class_id)]\n",
    "                color = (0, 255, 0)\n",
    "                cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.imshow('Object Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # return img,label\n",
    "\n",
    "image_path = '/home/sina/Desktop/prj/face_recognition/1234.png'  \n",
    "\n",
    "\n",
    "object_detection_from_image(image_path)\n",
    "# cv2.imshow('Object Detection', result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('n02123159', 'tiger_cat', 0.5627914),\n",
       " ('n02123045', 'tabby', 0.3619578),\n",
       " ('n02124075', 'Egyptian_cat', 0.07494959)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_image(cv2.imread(\"1234.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sina', 0.5608107)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_search_from_image(\"/home/sina/Desktop/prj/Pasted image.png\",0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/sina/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741198083.850717  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741198083.851244  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741198083.851418  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741198083.947078  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741198083.947403  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741198083.947563  120767 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-05 13:08:03.947702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1536 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:6b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import sqlite3\n",
    "import insightface\n",
    "\n",
    "# =====================\n",
    "# Configuration Settings\n",
    "# =====================\n",
    "\n",
    "IMG_SIZE = 112  # InsightFace models typically use 112x112 images\n",
    "FACE_THRESHOLD = 0.65\n",
    "GPU_MEM_LIMIT = 1536  # MB\n",
    "DATABASE_FILE = \"face_database.db\"\n",
    "CAPTURE_DIR = \"detected_faces\"\n",
    "MIN_CAPTURE_INTERVAL = 5  # seconds\n",
    "\n",
    "# =====================\n",
    "# Initialize Models\n",
    "# =====================\n",
    "\n",
    "# GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=GPU_MEM_LIMIT)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Config Error: {e}\")\n",
    "\n",
    "# Face Detection Model\n",
    "face_detector = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt\",\n",
    "    \"res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    ")\n",
    "\n",
    "# Face Embedding Model\n",
    "face_model = insightface.app.FaceAnalysis()\n",
    "face_model.prepare(ctx_id=0)\n",
    "\n",
    "# Image Classification Model\n",
    "classification_model = tf.keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# Database Functions\n",
    "# =====================\n",
    "def init_db():\n",
    "    \"\"\"Initialize SQLite database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS faces\n",
    "                (id INTEGER PRIMARY KEY, name TEXT, embedding BLOB)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def save_to_db(name, embedding):\n",
    "    \"\"\"Save face embedding to database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"INSERT INTO faces (name, embedding) VALUES (?, ?)\",\n",
    "             (name, embedding.tobytes()))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def load_from_db():\n",
    "    \"\"\"Load all face embeddings from database\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT name, embedding FROM faces\")\n",
    "    data = {row[0]: np.frombuffer(row[1], dtype=np.float32) for row in c.fetchall()}\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "# =====================\n",
    "# Image Processing\n",
    "# =====================\n",
    "def process_face(image):\n",
    "    \"\"\"Preprocess face image for embedding\"\"\"\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return (image / 127.5) - 1.0\n",
    "\n",
    "def get_embedding(image):\n",
    "    \"\"\"Generate face embedding\"\"\"\n",
    "    faces = face_model.get(image)\n",
    "    if faces:\n",
    "        return faces[0].embedding\n",
    "    return None\n",
    "\n",
    "def classify_image(image):\n",
    "    \"\"\"Classify image using ResNet50V2\"\"\"\n",
    "    img = cv2.resize(image, (224, 224))\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = classification_model.predict(np.expand_dims(img, 0))\n",
    "    return tf.keras.applications.resnet_v2.decode_predictions(preds, top=3)[0]\n",
    "\n",
    "def similarity_search(query_img, threshold):\n",
    "    \"\"\"Search for similar faces in database\"\"\"\n",
    "    embedding = get_embedding(query_img)\n",
    "    if embedding is None:\n",
    "        return []\n",
    "\n",
    "    database = load_from_db()\n",
    "    results = []\n",
    "    for name, db_emb in database.items():\n",
    "        similarity = cosine_similarity([embedding], [db_emb])[0][0]\n",
    "        if similarity >= threshold:\n",
    "            results.append((name, similarity))\n",
    "\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def similarity_search_from_image(image_path, thresh):\n",
    "    image = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    face_detector.setInput(blob)\n",
    "    detections = face_detector.forward()\n",
    "\n",
    "    faces = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0,0,i,2]\n",
    "        if confidence > 0.9:\n",
    "            box = detections[0,0,i,3:7] * np.array([image.shape[1], image.shape[0]]*2)\n",
    "            faces.append(box.astype(\"int\"))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = image[y:h, x:x+w]\n",
    "\n",
    "    return similarity_search(face_img, thresh)\n",
    "\n",
    "def webcam_face_identifier():\n",
    "    init_db()\n",
    "    os.makedirs(CAPTURE_DIR, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    db = load_from_db()\n",
    "    last_capture = {}\n",
    "    register_mode = False\n",
    "    embeddings = []\n",
    "    current_name = \"\"\n",
    "    known_embs = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        face_detector.setInput(blob)\n",
    "        detections = face_detector.forward()\n",
    "\n",
    "        faces = []\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0,0,i,2]\n",
    "            if confidence > 0.9:\n",
    "                box = detections[0,0,i,3:7] * np.array([frame.shape[1], frame.shape[0]]*2)\n",
    "                faces.append(box.astype(\"int\"))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:h, x:x+w]\n",
    "\n",
    "            if register_mode:\n",
    "                embeddings.append(get_embedding(face_img))\n",
    "                cv2.putText(frame, f\"Captured: {len(embeddings)}/50\", (x+5,y-30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "            else:\n",
    "                emb = get_embedding(face_img)\n",
    "                if emb is None:\n",
    "                    continue\n",
    "                best_match = (\"Unknown\", 0.0)\n",
    "                for name, db_emb in db.items():\n",
    "                    similarity = cosine_similarity([emb], [db_emb])[0][0]\n",
    "                    if similarity > best_match[1]:\n",
    "                        best_match = (name, similarity)\n",
    "\n",
    "                color = (0,255,0) if best_match[1] > FACE_THRESHOLD else (0,0,255)\n",
    "                cv2.rectangle(frame, (x,y), (w,h), color, 2)\n",
    "                cv2.putText(frame, f\"{best_match[0]} ({best_match[1]:.0%})\",\n",
    "                           (x+5,y-30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        db = load_from_db()\n",
    "\n",
    "        cv2.imshow('Smart Vision System', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            current_name = input(\"Enter name: \")\n",
    "            register_mode = True\n",
    "        elif key == ord(' ') and register_mode and len(embeddings) >= 50:\n",
    "            avg_emb = np.mean(embeddings, axis=0)\n",
    "            save_to_db(current_name, avg_emb)\n",
    "            db = load_from_db()\n",
    "            register_mode = False\n",
    "            embeddings = []\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def object_detection_from_webcam():\n",
    "    model_path = 'yolo11m.pt'\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.predict(frame)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                class_id = box.cls[0]\n",
    "                confidence = box.conf[0]\n",
    "\n",
    "                if confidence > 0.5:\n",
    "                    label = model.names[int(class_id)]\n",
    "                    color = (0, 255, 0)\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def object_detection_from_image(image_path):\n",
    "    model_path = \"yolo11m.pt\"\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    results = model.predict(img)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            class_id = box.cls[0]\n",
    "            confidence = box.conf[0]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                label = model.names[int(class_id)]\n",
    "                color = (0, 255, 0)\n",
    "                cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.imshow('Object Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "/home/sina/anaconda3/envs/tf/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "webcam_face_identifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
